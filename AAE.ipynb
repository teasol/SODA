{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy import io\n",
    "from scipy import sparse\n",
    "import scipy\n",
    "import gzip\n",
    "import scanpy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.distributions.beta import Beta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, mtx):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.mtx = mtx.tocsc()\n",
    "        self.number_of_genes, self.number_of_cells = mtx.shape\n",
    "    def __len__(self):\n",
    "        return self.number_of_cells\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.FloatTensor(np.asarray(self.mtx[:, idx].todense()).squeeze())        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaVAE(nn.Module):\n",
    "    def __init__(self, number_of_genes):\n",
    "        super(BetaVAE, self).__init__()\n",
    "\n",
    "        self.number_of_genes = number_of_genes\n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(self.number_of_genes, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.Linear(1000, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "        )\n",
    "        self.linear_a = nn.Linear(100, 10)\n",
    "        self.linear_b = nn.Linear(100, 10)\n",
    "\n",
    "\n",
    "        self.decode = nn.Linear(10, self.number_of_genes)\n",
    "        self.decode.weight.data.fill_(0.5)\n",
    "\n",
    "      \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        x = self.encode(x)\n",
    "        a = torch.exp(self.linear_a(x))\n",
    "        b = torch.exp(self.linear_b(x))\n",
    "\n",
    "        # Random sampling (reparametrization trick)\n",
    "        z = Beta(a, b).sample()\n",
    "\n",
    "        # Decoding\n",
    "        x_decoded = self.decode(z)\n",
    "\n",
    "        \n",
    "        return x_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, number_of_genes):\n",
    "        super(Critic, self).__init__()\n",
    "        self.number_of_genes = number_of_genes\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.number_of_genes, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.model(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_GP(object):\n",
    "    def __init__(self, number_of_genes):\n",
    "        self.device = \"cuda:0\"\n",
    "        self.learning_rate = 1e-4\n",
    "        self.n_critic = 5\n",
    "        self.n_generator = 100000\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.lambda_term = 10\n",
    "\n",
    "        self.generator = BetaVAE(number_of_genes).to(self.device)\n",
    "        self.critic = Critic(number_of_genes).to(self.device)\n",
    "\n",
    "        self.d_optimizer = optim.Adam(self.generator.parameters(), lr=self.learning_rate)\n",
    "        self.g_optimizer = optim.Adam(self.critic.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        for g_iter in range(self.n_generator):\n",
    "            for p in self.critic.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            for t in range(self.n_critic):\n",
    "                X = next(iter(train_loader))\n",
    "                X = X.to(self.device)\n",
    "                self.critic.zero_grad()\n",
    "\n",
    "                d_loss_real = self.critic(X)\n",
    "\n",
    "                fake_X = self.generator(X)\n",
    "                d_loss_fake = self.critic(fake_X)\n",
    "\n",
    "                gradient_penalty = self.calculate_gradient_penalty(X, fake_X)\n",
    "\n",
    "                d_loss = d_loss_fake - d_loss_real + gradient_penalty\n",
    "                d_loss = d_loss.mean()\n",
    "                d_loss.backward()\n",
    "                self.d_optimizer.step()                \n",
    "            for p in self.critic.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            X = next(iter(train_loader))\n",
    "            X = X.to(self.device)\n",
    "            \n",
    "            self.generator.zero_grad()\n",
    "            fake_cell = self.generator(X)\n",
    "            g_loss = -self.critic(fake_cell)\n",
    "            g_loss = g_loss.mean()\n",
    "            g_loss.backward()\n",
    "            self.g_optimizer.step()\n",
    "            self.generator.decode.weight.data.copy_(torch.sigmoid(self.generator.decode.weight.data))\n",
    "\n",
    "            if g_iter % 1000 == 0:\n",
    "                print(f'Generator iteration: {g_iter}/{self.n_generator}, g_loss: {g_loss},  d_loss:{d_loss}')\n",
    "\n",
    "        self.save_model()\n",
    "\n",
    "    def calculate_gradient_penalty(self, real_X, fake_X):\n",
    "        eta = torch.FloatTensor(1).uniform_(0,1)\n",
    "        eta = eta.expand(real_X.size())\n",
    "        eta = eta.to(self.device)\n",
    "\n",
    "        interpolated = eta * real_X + ((1 - eta) * fake_X)\n",
    "        interpolated = interpolated.to(self.device)\n",
    "        interpolated = Variable(interpolated, requires_grad=True)\n",
    "\n",
    "        prob_interpolated = self.critic(interpolated)\n",
    "\n",
    "        gradients = autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                               grad_outputs=torch.ones(prob_interpolated.size()).to(self.device),\n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "        \n",
    "        grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2) * self.lambda_term\n",
    "        \n",
    "        return grad_penalty\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.generator.state_dict(), './vae.pkl')\n",
    "        torch.save(self.critic.state_dict(), './critic.pkl')\n",
    "        print('Models save to ./vae.pkl & ./critic.pkl ')\n",
    "\n",
    "    def load_model(self, D_model_filename, G_model_filename):\n",
    "        D_model_path = os.path.join(os.getcwd(), D_model_filename)\n",
    "        G_model_path = os.path.join(os.getcwd(), G_model_filename)\n",
    "        self.D.load_state_dict(torch.load(D_model_path))\n",
    "        self.G.load_state_dict(torch.load(G_model_path))\n",
    "        print('Generator model loaded from {}.'.format(G_model_path))\n",
    "        print('Discriminator model loaded from {}-'.format(D_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = \"/data/home/kimds/Data/Normalized/\"\n",
    "census = io.mmread(DIR_PATH+'census.mtx')\n",
    "heart = io.mmread(DIR_PATH+'heart.mtx')\n",
    "immune = io.mmread(DIR_PATH+'immune.mtx')\n",
    "# covid = io.mmread(DIR_PATH+'covid.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sparse.hstack([census, heart, immune])\n",
    "number_of_genes = data.shape[0]\n",
    "\n",
    "dataset = CustomDataset(data)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator iteration: 0/10000, g_loss: -0.14824743568897247,  d_loss:9.305519104003906\n",
      "Generator iteration: 100/10000, g_loss: 2191.6279296875,  d_loss:-1974.128662109375\n",
      "Generator iteration: 200/10000, g_loss: 11148.28515625,  d_loss:-6268.4951171875\n",
      "Generator iteration: 300/10000, g_loss: 13862.2216796875,  d_loss:-8646.791015625\n",
      "Generator iteration: 400/10000, g_loss: 15224.134765625,  d_loss:-7156.6171875\n",
      "Generator iteration: 500/10000, g_loss: 14187.04296875,  d_loss:-9668.359375\n",
      "Generator iteration: 600/10000, g_loss: 16328.1826171875,  d_loss:-6345.126953125\n",
      "Generator iteration: 700/10000, g_loss: 18065.271484375,  d_loss:-10336.634765625\n",
      "Generator iteration: 800/10000, g_loss: 15958.6201171875,  d_loss:-6882.3388671875\n",
      "Generator iteration: 900/10000, g_loss: 16785.103515625,  d_loss:-10694.08203125\n",
      "Generator iteration: 1000/10000, g_loss: 15800.9521484375,  d_loss:-10623.8046875\n",
      "Generator iteration: 1100/10000, g_loss: 20280.56640625,  d_loss:-11521.501953125\n",
      "Generator iteration: 1200/10000, g_loss: 18646.40625,  d_loss:-6245.65478515625\n",
      "Generator iteration: 1300/10000, g_loss: 19622.095703125,  d_loss:-5212.48486328125\n",
      "Generator iteration: 1400/10000, g_loss: 13737.423828125,  d_loss:-11445.2978515625\n",
      "Generator iteration: 1500/10000, g_loss: 18814.35546875,  d_loss:-5981.6162109375\n",
      "Generator iteration: 1600/10000, g_loss: 18226.93359375,  d_loss:-8956.1298828125\n",
      "Generator iteration: 1700/10000, g_loss: 20179.55078125,  d_loss:-11674.322265625\n",
      "Generator iteration: 1800/10000, g_loss: 19545.748046875,  d_loss:-10483.615234375\n",
      "Generator iteration: 1900/10000, g_loss: 19082.287109375,  d_loss:-14297.5791015625\n",
      "Generator iteration: 2000/10000, g_loss: 20154.98828125,  d_loss:-10147.4091796875\n",
      "Generator iteration: 2100/10000, g_loss: 22099.228515625,  d_loss:-9042.109375\n",
      "Generator iteration: 2200/10000, g_loss: 19589.56640625,  d_loss:-10186.375\n",
      "Generator iteration: 2300/10000, g_loss: 20749.859375,  d_loss:-14927.5625\n",
      "Generator iteration: 2400/10000, g_loss: 26138.8984375,  d_loss:-11722.22265625\n",
      "Generator iteration: 2500/10000, g_loss: 23599.30078125,  d_loss:-11040.46875\n",
      "Generator iteration: 2600/10000, g_loss: 28807.751953125,  d_loss:-10704.5087890625\n",
      "Generator iteration: 2700/10000, g_loss: 21390.970703125,  d_loss:-12632.21875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/home/kimds/SODA/AAE.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bs1/data/home/kimds/SODA/AAE.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m aae \u001b[39m=\u001b[39m WGAN_GP(number_of_genes)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bs1/data/home/kimds/SODA/AAE.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m aae\u001b[39m.\u001b[39;49mtrain(train_loader)\n",
      "\u001b[1;32m/data/home/kimds/SODA/AAE.ipynb Cell 8\u001b[0m in \u001b[0;36mWGAN_GP.train\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bs1/data/home/kimds/SODA/AAE.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     p\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bs1/data/home/kimds/SODA/AAE.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_critic):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bs1/data/home/kimds/SODA/AAE.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_loader))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bs1/data/home/kimds/SODA/AAE.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bs1/data/home/kimds/SODA/AAE.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/TORCH/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/TORCH/lib/python3.8/site-packages/torch/utils/data/dataloader.py:691\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/anaconda3/envs/TORCH/lib/python3.8/site-packages/torch/utils/data/dataloader.py:642\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 642\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampler_iter)\n",
      "File \u001b[0;32m~/anaconda3/envs/TORCH/lib/python3.8/site-packages/torch/utils/data/sampler.py:240\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m         batch \u001b[39m=\u001b[39m [\u001b[39mnext\u001b[39m(sampler_iter) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)]\n\u001b[1;32m    241\u001b[0m         \u001b[39myield\u001b[39;00m batch\n\u001b[1;32m    242\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/TORCH/lib/python3.8/site-packages/torch/utils/data/sampler.py:240\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m         batch \u001b[39m=\u001b[39m [\u001b[39mnext\u001b[39;49m(sampler_iter) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)]\n\u001b[1;32m    241\u001b[0m         \u001b[39myield\u001b[39;00m batch\n\u001b[1;32m    242\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/TORCH/lib/python3.8/site-packages/torch/utils/data/sampler.py:132\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n):\n\u001b[0;32m--> 132\u001b[0m         \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39;49mrandperm(n, generator\u001b[39m=\u001b[39;49mgenerator)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    133\u001b[0m     \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39mrandperm(n, generator\u001b[39m=\u001b[39mgenerator)\u001b[39m.\u001b[39mtolist()[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m%\u001b[39m n]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aae = WGAN_GP(number_of_genes)\n",
    "aae.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('TORCH': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d12e7c042276a4aee0aba75551736f84218c16c7b0909dd9737c86aed213d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
