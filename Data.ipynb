{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy import io\n",
    "from scipy import sparse\n",
    "import scipy\n",
    "import gzip\n",
    "import scanpy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.distributions.beta import Beta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "/data/home/kimds/anaconda3/envs/TORCH/lib/python3.8/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/data/home/kimds/anaconda3/envs/TORCH/lib/python3.8/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/data/home/kimds/anaconda3/envs/TORCH/lib/python3.8/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/data/home/kimds/anaconda3/envs/TORCH/lib/python3.8/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "# 0 A Census of Immune Cells\n",
    "# ~ 71 min\n",
    "DIR_PATH = \"/data/home/kimds/Data/A Census of Immune Cells\"\n",
    "census_blood = scanpy.read_loom(DIR_PATH + \"/1M-immune-human-blood-10XV2.loom\")\n",
    "census_immune = scanpy.read_loom(DIR_PATH + \"/1M-immune-human-immune-10XV2.loom\")\n",
    "census_of_immune_cells_genes = pd.read_csv(DIR_PATH+'/genes.csv')\n",
    "\n",
    "census_blood.obs_names_make_unique()\n",
    "census_blood.var_names_make_unique()\n",
    "census_immune.obs_names_make_unique()\n",
    "census_immune.var_names_make_unique()\n",
    "\n",
    "census_raw = sparse.vstack([census_blood.X, census_immune.X]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Heart Cell Atlas\n",
    "# ~ 1 min\n",
    "DIR_PATH = '/data/home/kimds/Data/Heart Cell Atlas'\n",
    "heart_raw = io.mmread(DIR_PATH+'/'+'sparse_mtx.mtx')\n",
    "heart_genes = pd.read_csv(DIR_PATH+'/genes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Immune Cell Atlas\n",
    "# ~ 16 min\n",
    "DIR_PATH = '/data/home/kimds/Data/Immune Cell Atlas'\n",
    "immune_raw = io.mmread(DIR_PATH+'/'+'sparse_mtx.mtx')\n",
    "immune_genes = pd.read_csv(DIR_PATH+'/genes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Immune Cells in Critical COVID19\n",
    "# ~ 60 min\n",
    "DIR_PATH = '/data/home/kimds/Data/Immune Cells in Critical COVID19'\n",
    "FILE_PATH = '/data/home/kimds/Data/Immune Cells in Critical COVID19/GSE158055_covid19_counts.mtx.gz'\n",
    "covid_raw = io.mmread(FILE_PATH)\n",
    "covid_features = pd.read_csv(DIR_PATH+'/GSE158055_covid19_features.tsv.gz', sep='\\t', compression='gzip', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_genes = census_blood.var.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = '/data/home/kimds/Data/Heart Cell Atlas'\n",
    "heart_genes = pd.read_csv(DIR_PATH+'/genes.csv')\n",
    "heart_genes = heart_genes.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = '/data/home/kimds/Data/Immune Cell Atlas'\n",
    "immune_genes = pd.read_csv(DIR_PATH+'/genes.csv')\n",
    "immune_genes = immune_genes.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = '/data/home/kimds/Data/Immune Cells in Critical COVID19'\n",
    "covid_features = pd.read_csv(DIR_PATH+'/GSE158055_covid19_features.tsv.gz', sep='\\t', compression='gzip', header=None)\n",
    "covid_genes = covid_features.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = census_genes\n",
    "temp = temp[temp.isin(heart_genes)]\n",
    "temp = temp[temp.isin(immune_genes)]\n",
    "temp = temp[temp.isin(covid_genes)]\n",
    "census_indices = census_genes.isin(temp)\n",
    "heart_indices = heart_genes.isin(temp)\n",
    "immune_indices = immune_genes.isin(temp)\n",
    "covid_indices = covid_genes.isin(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_genes = len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = census_raw.tocsc()[census_indices, :]\n",
    "heart = heart_raw.tocsc()[heart_indices, :]\n",
    "immune = immune_raw.tocsc()[immune_indices, :]\n",
    "covid = covid_raw.tocsc()[covid_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26326x2665987 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3483512308 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sparse.hstack([census, heart, immune, covid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "io.mmwrite(\"/data/home/kimds/Data/data.mtx\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, mtx):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.mtx = mtx.tocsc()\n",
    "        self.number_of_genes, self.number_of_cells = mtx.shape\n",
    "    def __len__(self):\n",
    "        return self.number_of_cells\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.FloatTensor(np.asarray(self.mtx[:, idx].todense()).squeeze())        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mtx, C=1e4):\n",
    "    mtx = mtx.tocsc()\n",
    "    new_mtx = mtx.astype(np.float64)\n",
    "    for j in range(len(mtx.indptr)-1):\n",
    "        index_0 = mtx.indptr[j]\n",
    "        index_1 = mtx.indptr[j+1]\n",
    "        new_mtx.data[index_0:index_1] = np.log(C*mtx.data[index_0:index_1]/np.sum(mtx.data[index_0:index_1]+1))\n",
    "    return new_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp Data\n",
    "heart = normalize(heart_raw)\n",
    "number_of_genes = heart.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaVAE(nn.Module):\n",
    "    def __init__(self, number_of_genes):\n",
    "        super(BetaVAE, self).__init__()\n",
    "\n",
    "        self.number_of_genes = number_of_genes\n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(self.number_of_genes, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.Linear(1000, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Dropout(),\n",
    "        )\n",
    "        self.linear_a = nn.Linear(100, 10)\n",
    "        self.linear_b = nn.Linear(100, 10)\n",
    "\n",
    "\n",
    "        self.decode = nn.Linear(10, self.number_of_genes)\n",
    "        self.decode.weight.data.fill_(0.5)\n",
    "\n",
    "      \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        x = self.encode(x)\n",
    "        a = torch.exp(self.linear_a(x))\n",
    "        b = torch.exp(self.linear_b(x))\n",
    "\n",
    "        # Random sampling (reparametrization trick)\n",
    "        z = Beta(a, b).sample()\n",
    "\n",
    "        # Decoding\n",
    "        x_decoded = self.decode(z)\n",
    "\n",
    "        \n",
    "        return x_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_dataloader, optim, epoch):\n",
    "    mse = nn.MSELoss()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, X in enumerate(train_dataloader):\n",
    "        X = X.to(device)\n",
    "        optim.zero_grad()\n",
    "        pred = model.forward(X)\n",
    "        loss = mse(pred, X)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        model.decode.weight.data.copy_(torch.sigmoid(model.decode.weight.data))\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    if epoch % 1 == 0:\n",
    "        print('epoch', epoch)\n",
    "        print('TRAIN loss =', average_loss*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "TRAIN loss = 11275.272805552713\n",
      "epoch 1\n",
      "TRAIN loss = 11277.879597062423\n",
      "epoch 2\n",
      "TRAIN loss = 11275.199492399308\n",
      "epoch 3\n",
      "TRAIN loss = 11255.741848445648\n",
      "epoch 4\n",
      "TRAIN loss = 11233.660024842931\n",
      "epoch 5\n",
      "TRAIN loss = 11213.731784775784\n",
      "epoch 6\n",
      "TRAIN loss = 11208.05742520495\n",
      "epoch 7\n",
      "TRAIN loss = 11214.231879125366\n",
      "epoch 8\n",
      "TRAIN loss = 11175.556101522907\n",
      "epoch 9\n",
      "TRAIN loss = 11156.556118262206\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(heart)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "device = 'cuda:0'\n",
    "vae = BetaVAE(number_of_genes).to(device)\n",
    "learning_rate = 0.000002\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train(vae, device, train_loader, optimizer, epoch)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, number_of_genes):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.number_of_genes = number_of_genes\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.number_of_genes, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        z = torch.sigmoid(x)\n",
    "        return z\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, device, train_loader, vae, discriminator, gen_opt, disc_opt):\n",
    "    vae.train()\n",
    "    discriminator.train()\n",
    "    total_g = 0\n",
    "    total_d = 0\n",
    "\n",
    "    bce = nn.BCELoss()\n",
    "\n",
    "    for X in train_loader:\n",
    "        X = X.to(device)\n",
    "\n",
    "        size = discriminator(X).size()\n",
    "        ones = torch.ones(size, requires_grad=False).to(device)\n",
    "        zeros = torch.zeros(size, requires_grad=False).to(device)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        X_ = vae(X)\n",
    "        gen_loss = bce(discriminator(X_), ones)\n",
    "        gen_loss.backward()\n",
    "        total_g += gen_loss.item()\n",
    "        gen_opt.step()\n",
    "\n",
    "        disc_opt.zero_grad()        \n",
    "        actual_loss = bce(discriminator(X), ones)\n",
    "        fake_loss = bce(discriminator(X_.detach()), zeros)\n",
    "        disc_loss = (actual_loss + fake_loss) / 2\n",
    "        disc_loss.backward()\n",
    "        total_d += disc_loss.item()\n",
    "        disc_opt.step()\n",
    "    if epoch % 1 == 0:\n",
    "        print('epoch', epoch, 'G', total_g/len(train_loader), 'D', total_d/len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immune_dataset = CustomDataset(immune)\n",
    "dataset = immune_dataset\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = 'cuda:4'\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "vae = BetaVAE(number_of_genes)\n",
    "vae.load_state_dict(torch.load('/data/home/kimds/GAN/betavae.pt'))\n",
    "discriminator = Discriminator(number_of_genes)\n",
    "gen_opt = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "disc_opt = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(epoch, device, train_loader, vae, discriminator, gen_opt, disc_opt)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('TORCH': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d12e7c042276a4aee0aba75551736f84218c16c7b0909dd9737c86aed213d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
